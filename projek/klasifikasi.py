# -*- coding: utf-8 -*-
"""Copy of [Klasifikasi] Submission Akhir BMLP_Your Name.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1TfYCp-0btUFOPZgYuTru3Q-IHjqVGPUw

# **1. Import Library**

Pada tahap ini, Anda perlu mengimpor beberapa pustaka (library) Python yang dibutuhkan untuk analisis data dan pembangunan model machine learning.
"""

#Type your code here
import pandas as pd
import numpy as np
from sklearn.model_selection import train_test_split
from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import classification_report, accuracy_score, confusion_matrix
import seaborn as sns
import matplotlib.pyplot as plt
from sklearn.model_selection import GridSearchCV

"""# **2. Memuat Dataset dari Hasil Clustering**

Memuat dataset hasil clustering dari file CSV ke dalam variabel DataFrame.
"""

#Type your code here
pd.options.display.max_columns = None
file_path = 'clustered_data.csv'
df = pd.read_csv(file_path)

# Drop 'CustomerID' as it's not relevant for classification
df = df.drop(columns=['CustomerID'])

# Display dataset info
print(df.head())
print(df.info())

"""# **3. Data Splitting**

Tahap Data Splitting bertujuan untuk memisahkan dataset menjadi dua bagian: data latih (training set) dan data uji (test set).
"""

#Type your code here
X = df.drop('Cluster', axis=1)
y = df['Cluster']

# Bagi dataset menjadi data latih dan uji
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# Tampilkan ukuran data latih dan uji
print("Training data shape:", X_train.shape)
print("Test data shape:", X_test.shape)

"""# **4. Membangun Model Klasifikasi**

## **a. Membangun Model Klasifikasi**

Setelah memilih algoritma klasifikasi yang sesuai, langkah selanjutnya adalah melatih model menggunakan data latih.

Berikut adalah rekomendasi tahapannya.
1. Pilih algoritma klasifikasi yang sesuai, seperti Logistic Regression, Decision Tree, Random Forest, atau K-Nearest Neighbors (KNN).
2. Latih model menggunakan data latih.
"""

#Type your code here
# Inisialisasi model Random Forest
clf = RandomForestClassifier(random_state=42)

# Latih model menggunakan data latih
clf.fit(X_train, y_train)

"""Tulis narasi atau penjelasan algoritma yang Anda gunakan.

## **b. Evaluasi Model Klasifikasi**

Berikut adalah **rekomendasi** tahapannya.
1. Lakukan prediksi menggunakan data uji.
2. Hitung metrik evaluasi seperti Accuracy dan F1-Score (Opsional: Precision dan Recall).
3. Buat confusion matrix untuk melihat detail prediksi benar dan salah.
"""

#Type your code here
# Prediksi pada data uji
y_pred = clf.predict(X_test)

# Evaluasi model
print("Accuracy:", accuracy_score(y_test, y_pred))
print("\nClassification Report:\n", classification_report(y_test, y_pred))

# Confusion Matrix
conf_matrix = confusion_matrix(y_test, y_pred)
plt.figure(figsize=(8, 6))
sns.heatmap(conf_matrix, annot=True, fmt='d', cmap='Blues', xticklabels=clf.classes_, yticklabels=clf.classes_)
plt.title('Confusion Matrix')
plt.xlabel('Predicted Label')
plt.ylabel('True Label')
plt.show()

"""Tulis hasil evaluasi algoritma yang digunakan, jika Anda menggunakan 2 algoritma, maka bandingkan hasilnya.

## **c. Tuning Model Klasifikasi (Optional)**

Gunakan GridSearchCV, RandomizedSearchCV, atau metode lainnya untuk mencari kombinasi hyperparameter terbaik
"""

#Type your code here
# Parameter grid untuk Random Forest
param_grid = {
    'n_estimators': [50, 100, 150],
    'max_depth': [None, 10, 20, 30],
    'min_samples_split': [2, 5, 10],
    'min_samples_leaf': [1, 2, 4]
}

# Inisialisasi GridSearchCV
grid_search = GridSearchCV(estimator=RandomForestClassifier(random_state=42),
                           param_grid=param_grid,
                           cv=3,
                           scoring='accuracy',
                           n_jobs=-1)
# Latih model
grid_search.fit(X_train, y_train)

# Parameter terbaik
print("Best Parameters:", grid_search.best_params_)

# Model terbaik
best_model = grid_search.best_estimator_

# Evaluasi ulang dengan model terbaik
y_pred_best = best_model.predict(X_test)
print("\nAccuracy after tuning:", accuracy_score(y_test, y_pred_best))

"""## **d. Evaluasi Model Klasifikasi setelah Tuning (Optional)**

Berikut adalah rekomendasi tahapannya.
1. Gunakan model dengan hyperparameter terbaik.
2. Hitung ulang metrik evaluasi untuk melihat apakah ada peningkatan performa.
"""

#Type your code here
# Evaluasi ulang confusion matrix setelah tuning
conf_matrix_best = confusion_matrix(y_test, y_pred_best)
plt.figure(figsize=(8, 6))
sns.heatmap(conf_matrix_best, annot=True, fmt='d', cmap='Blues', xticklabels=best_model.classes_, yticklabels=best_model.classes_)
plt.title('Confusion Matrix After Tuning')
plt.xlabel('Predicted Label')
plt.ylabel('True Label')
plt.show()

"""## **e. Analisis Hasil Evaluasi Model Klasifikasi**

Berikut adalah **rekomendasi** tahapannya.
1. Bandingkan hasil evaluasi sebelum dan setelah tuning (jika dilakukan).
2. Identifikasi kelemahan model, seperti:
  - Precision atau Recall rendah untuk kelas tertentu.
  - Apakah model mengalami overfitting atau underfitting?
3. Berikan rekomendasi tindakan lanjutan, seperti mengumpulkan data tambahan atau mencoba algoritma lain jika hasil belum memuaskan.
"""

"""
Perbandingan Hasil Evaluasi Sebelum dan Setelah Tuning:

Sebelum Tuning:
Akurasi model mencapai 0.94, dengan nilai rata-rata Precision, Recall, dan F1-Score yang cukup tinggi untuk semua kelas.
Setelah Tuning:
Akurasi menurun menjadi 0.9325, meskipun perbedaan ini tidak signifikan. Penurunan ini dapat terjadi karena parameter tuning menghasilkan model yang lebih sederhana atau menghindari overfitting.
Identifikasi Kelemahan Model:

Precision atau Recall Rendah untuk Kelas Tertentu:
Tidak ada kelas dengan Precision atau Recall yang sangat rendah, tetapi perbedaan kecil antara Precision (0.92) dan Recall (0.94) untuk kelas 0 menunjukkan ada ruang untuk perbaikan pada kelas ini.
Overfitting atau Underfitting:
Sebelum tuning, model menunjukkan potensi overfitting karena akurasi tinggi di data training (tidak disebutkan di sini). Setelah tuning, model tampaknya lebih teratur, meskipun akurasi sedikit menurun.
Rekomendasi Tindakan Lanjutan:

Pengumpulan Data Tambahan:
Jika memungkinkan, kumpulkan data tambahan untuk memperbaiki generalisasi model, khususnya untuk kelas 0 yang menunjukkan sedikit ketidakseimbangan antara Precision dan Recall.
Eksperimen dengan Algoritma Lain:
Cobalah algoritma lain seperti Random Forest, Gradient Boosting, atau XGBoost, yang mungkin memberikan kinerja lebih baik untuk dataset ini.
Pemrosesan Data dan Penyeimbangan Kelas:
Analisis distribusi data untuk memastikan tidak ada ketidakseimbangan yang signifikan di antara kelas-kelas. Jika ada, pertimbangkan metode penyeimbangan seperti oversampling atau undersampling.
Validasi yang Lebih Mendalam:
Gunakan k-fold cross-validation untuk memastikan hasil evaluasi lebih konsisten.
"""